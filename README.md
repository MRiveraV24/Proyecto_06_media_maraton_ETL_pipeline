# ğŸƒ Pipeline Analytics - Media MaratÃ³n La Serena 2024

[![Apache Airflow](https://img.shields.io/badge/Apache%20Airflow-2.8.1-017CEE?logo=apache-airflow)](https://airflow.apache.org/)
[![Python](https://img.shields.io/badge/Python-3.11-3776AB?logo=python)](https://python.org/)
[![Docker](https://img.shields.io/badge/Docker-Compose-2496ED?logo=docker)](https://docker.com/)
[![Pandas](https://img.shields.io/badge/Pandas-2.1.4-150458?logo=pandas)](https://pandas.pydata.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Status](https://img.shields.io/badge/Status-Production-success)]()

---

## ğŸ“‹ Tabla de Contenidos

1. [Objetivos](#-objetivos)
2. [DescripciÃ³n del Conjunto de Datos](#-descripciÃ³n-del-conjunto-de-datos)
3. [Stack TecnolÃ³gico](#-stack-tecnolÃ³gico)
4. [Arquitectura del Proyecto](#-arquitectura-del-proyecto)
5. [Flujo de los Datos](#-flujo-de-los-datos)
6. [Calidad de los Datos](#-calidad-de-los-datos)
7. [InstalaciÃ³n y ConfiguraciÃ³n](#-instalaciÃ³n-y-configuraciÃ³n)
8. [Uso del Pipeline](#-uso-del-pipeline)
9. [Estructura del Proyecto](#-estructura-del-proyecto)
10. [KPIs Generados](#-kpis-generados)
11. [Monitoreo y Logs](#-monitoreo-y-logs)
12. [Troubleshooting](#-troubleshooting)
13. [Roadmap](#-roadmap)
14. [Contribuciones](#-contribuciones)
15. [Licencia](#-licencia)
16. [Contacto](#-contacto)

---

## ğŸ¯ Objetivos

### Objetivo General

Desarrollar un **pipeline de datos end-to-end automatizado y escalable** que procese los resultados de la Media MaratÃ³n La Serena 2024, transformando datos crudos y desestructurados en insights accionables para anÃ¡lisis deportivo y toma de decisiones.

### Objetivos EspecÃ­ficos

1. **Ingesta Automatizada**: Implementar un sistema de captura de datos que simule la recepciÃ³n de archivos de resultados de carreras en formatos poco estructurados.

2. **Limpieza y TransformaciÃ³n**: Aplicar tÃ©cnicas avanzadas de data wrangling con Pandas y expresiones regulares para:
   - Separar campos concatenados (categorÃ­a y nÃºmero de dorsal)
   - Normalizar nombres de corredores
   - Convertir formatos de tiempo a mÃ©tricas calculables
   - Estandarizar tipos de datos

3. **GeneraciÃ³n de MÃ©tricas de Valor**: Crear KPIs especÃ­ficos del dominio deportivo:
   - Tiempos promedio por categorÃ­a y gÃ©nero
   - Rankings por velocidad y ritmo
   - DistribuciÃ³n demogrÃ¡fica de participantes
   - AnÃ¡lisis de rendimiento comparativo

4. **OrquestaciÃ³n Robusta**: Utilizar Apache Airflow para:
   - Automatizar la ejecuciÃ³n del pipeline
   - Gestionar dependencias entre tareas
   - Implementar reintentos automÃ¡ticos ante fallos
   - Facilitar el monitoreo y debugging

5. **ContainerizaciÃ³n**: Emplear Docker para garantizar:
   - Reproducibilidad del entorno
   - Portabilidad entre diferentes sistemas operativos
   - Aislamiento de dependencias
   - Facilidad de despliegue

6. **ImplementaciÃ³n de Best Practices**: Aplicar principios de ingenierÃ­a de datos moderna:
   - Arquitectura Medallion (Bronze-Silver-Gold)
   - SeparaciÃ³n de responsabilidades
   - Logging estructurado
   - Manejo de errores robusto
   - CÃ³digo documentado y mantenible

---

## ğŸ“Š DescripciÃ³n del Conjunto de Datos

### Origen de los Datos

Los datos simulan resultados oficiales de la **Media MaratÃ³n La Serena 2024** (21.1 km), representando el formato tÃ­pico en que organizadores de eventos deportivos entregan informaciÃ³n: archivos CSV o Excel con campos concatenados y formatos inconsistentes.

### CaracterÃ­sticas del Dataset

| CaracterÃ­stica | Valor |
|----------------|-------|
| **NÃºmero de registros** | 25 corredores |
| **Formato original** | CSV con campos concatenados |
| **Distancia de carrera** | 21.1 km (media maratÃ³n) |
| **CategorÃ­as incluidas** | 7 categorÃ­as (por gÃ©nero y rango etario) |
| **Periodo simulado** | 2024 |

### Variables del Dataset Original (Bronze)

#### ğŸ“¥ Datos de Entrada (Raw)

| Variable | Tipo | DescripciÃ³n | Ejemplo | Problemas Comunes |
|----------|------|-------------|---------|-------------------|
| `pos_general` | String | PosiciÃ³n general en la carrera | `"127Âº"` | Incluye sÃ­mbolo "Âº" |
| `pos_categoria` | String | PosiciÃ³n dentro de su categorÃ­a | `"47Âº"` | Incluye sÃ­mbolo "Âº" |
| `nombre_corredor` | String | Nombre completo del participante | `"Abel Ballon Aguirre"` | CapitalizaciÃ³n inconsistente |
| `categoria_dorsal` | String | **Campo problemÃ¡tico**: CategorÃ­a + dorsal concatenados | `"Varones 30 a 39 aÃ±osdorsal: 2395"` | Sin separador, requiere regex |
| `tiempo_oficial` | String | Tiempo en formato H:MM:SS | `"1:46:32"` | String, no numÃ©rico |

#### ğŸ” Ejemplo de Registro Crudo

```csv
pos_general,pos_categoria,nombre_corredor,categoria_dorsal,tiempo_oficial
127Âº,47Âº,Abel Ballon Aguirre,Varones 30 a 39 aÃ±osdorsal: 2395,1:46:32
```

**Problemas identificados:**
- âŒ SÃ­mbolos "Âº" en posiciones
- âŒ Campo `categoria_dorsal` requiere parsing complejo
- âŒ Nombres pueden estar en minÃºsculas
- âŒ Tiempo como string no permite cÃ¡lculos

---

### Variables del Dataset Transformado (Silver)

#### ğŸ“¤ Datos de Salida (Clean)

DespuÃ©s del procesamiento en la capa Silver, los datos se estructuran asÃ­:

| Variable | Tipo | DescripciÃ³n | Ejemplo | TransformaciÃ³n Aplicada |
|----------|------|-------------|---------|-------------------------|
| `pos_general` | Integer | PosiciÃ³n general (numÃ©rica) | `127` | Remover "Âº", convertir a int |
| `pos_categoria` | Integer | PosiciÃ³n en categorÃ­a (numÃ©rica) | `47` | Remover "Âº", convertir a int |
| `dorsal` | Integer | NÃºmero de dorsal del corredor | `2395` | ExtraÃ­do con regex |
| `nombre_corredor` | String | Nombre normalizado | `"Abel Ballon Aguirre"` | Title case aplicado |
| `genero` | String | GÃ©nero del corredor | `"Varones"` | ExtraÃ­do con regex |
| `rango_edad` | String | Rango etario | `"30 a 39 aÃ±os"` | ExtraÃ­do con regex |
| `categoria` | String | CategorÃ­a completa | `"Varones 30 a 39 aÃ±os"` | Reconstruida |
| `tiempo_oficial` | String | Tiempo original (referencia) | `"1:46:32"` | Conservado |
| `tiempo_segundos` | Integer | Tiempo total en segundos | `6392` | Calculado: H*3600 + M*60 + S |
| `ritmo_min_km` | String | Ritmo promedio por km | `"5:03"` | Calculado: tiempo / 21.1 km |
| `velocidad_kmh` | Float | Velocidad promedio | `11.86` | Calculada: 21.1 / (tiempo/3600) |

#### ğŸ” Ejemplo de Registro Limpio

```csv
pos_general,pos_categoria,dorsal,nombre_corredor,genero,rango_edad,categoria,tiempo_oficial,tiempo_segundos,ritmo_min_km,velocidad_kmh
127,47,2395,Abel Ballon Aguirre,Varones,30 a 39 aÃ±os,Varones 30 a 39 aÃ±os,1:46:32,6392,5:03,11.86
```

---

### CategorÃ­as de Corredores

El dataset incluye las siguientes categorÃ­as, reflejando la estructura tÃ­pica de carreras:

| CategorÃ­a | GÃ©nero | Rango Etario | Participantes en Dataset |
|-----------|--------|--------------|--------------------------|
| Varones 18 a 29 aÃ±os | Masculino | 18-29 | 2 |
| Varones 30 a 39 aÃ±os | Masculino | 30-39 | 6 |
| Varones 40 a 49 aÃ±os | Masculino | 40-49 | 2 |
| Varones 50 a 59 aÃ±os | Masculino | 50-59 | 2 |
| Varones 60+ aÃ±os | Masculino | 60+ | 2 |
| Damas 18 a 29 aÃ±os | Femenino | 18-29 | 2 |
| Damas 30 a 39 aÃ±os | Femenino | 30-39 | 2 |
| Damas 40 a 49 aÃ±os | Femenino | 40-49 | 4 |
| Damas 50 a 59 aÃ±os | Femenino | 50-59 | 2 |
| Damas 60+ aÃ±os | Femenino | 60+ | 1 |

### EstadÃ­sticas Descriptivas del Dataset

```
Total de Corredores: 25
â”œâ”€ Varones: 17 (68%)
â””â”€ Damas: 8 (32%)

Tiempo mÃ¡s rÃ¡pido: 1:12:45 (Carlos AndrÃ©s DÃ­az Moreno)
Tiempo mÃ¡s lento: 2:30:15 (Gabriela Fernanda RÃ­os)
Tiempo promedio: ~1:51:00
Ritmo promedio: ~5:16 min/km
```

---

## ğŸ› ï¸ Stack TecnolÃ³gico

### OrquestaciÃ³n y Workflow

| TecnologÃ­a | VersiÃ³n | PropÃ³sito | JustificaciÃ³n |
|------------|---------|-----------|---------------|
| **Apache Airflow** | 2.8.1 | Orquestador de workflows | EstÃ¡ndar de industria para pipelines complejos. Ofrece UI web, scheduler robusto, y gestiÃ³n de dependencias. |
| **Python** | 3.11 | Lenguaje de programaciÃ³n principal | Ecosistema rico en librerÃ­as de datos. Sintaxis clara y amplia adopciÃ³n en Data Engineering. |

### Procesamiento de Datos

| TecnologÃ­a | VersiÃ³n | PropÃ³sito | JustificaciÃ³n |
|------------|---------|-----------|---------------|
| **Pandas** | 2.1.4 | ManipulaciÃ³n y anÃ¡lisis de datos | LibrerÃ­a lÃ­der para data wrangling. API intuitiva para transformaciones complejas. |
| **Regex (re)** | Built-in | Parsing de strings complejos | Esencial para extraer informaciÃ³n de campos concatenados sin estructura fija. |
| **OpenPyXL** | 3.1.2 | Lectura de archivos Excel | Soporte completo para formatos .xlsx modernos. |

### Infraestructura y Despliegue

| TecnologÃ­a | VersiÃ³n | PropÃ³sito | JustificaciÃ³n |
|------------|---------|-----------|---------------|
| **Docker** | 24.x | ContainerizaciÃ³n | Garantiza reproducibilidad del entorno. Simplifica despliegue multi-plataforma. |
| **Docker Compose** | 2.x | OrquestaciÃ³n de contenedores | Gestiona mÃºltiples servicios (Airflow, PostgreSQL) con un solo comando. |
| **PostgreSQL** | 15 | Base de datos de metadatos | Backend estÃ¡ndar de Airflow. Alta confiabilidad y rendimiento. |

### Control de Versiones y DocumentaciÃ³n

| TecnologÃ­a | VersiÃ³n | PropÃ³sito | JustificaciÃ³n |
|------------|---------|-----------|---------------|
| **Git** | - | Control de versiones | EstÃ¡ndar de industria para versionado de cÃ³digo. |
| **Markdown** | - | DocumentaciÃ³n | Formato universal, legible y compatible con Git. |

### Desarrollo y Testing

| TecnologÃ­a | VersiÃ³n | PropÃ³sito |
|------------|---------|-----------|
| **Logging** | Built-in Python | Trazabilidad y debugging |
| **Pathlib** | Built-in Python | Manejo de rutas multiplataforma |
| **Type Hints** | Python 3.11+ | DocumentaciÃ³n de tipos y mejor IDE support |

---

## ğŸ—ï¸ Arquitectura del Proyecto

### Arquitectura Medallion (Bronze-Silver-Gold)

Este proyecto implementa el patrÃ³n **Medallion Architecture**, popularizado por Databricks y considerado best practice en lakehouse architecture.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     APACHE AIRFLOW (Orchestrator)               â”‚
â”‚                                                                 â”‚
â”‚  DAG: pipeline_media_maraton_la_serena_2024                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  Bronze  â”‚â†’ â”‚  Silver  â”‚â†’ â”‚   Gold   â”‚â†’ â”‚ Validate â”‚      â”‚
â”‚  â”‚ Ingesta  â”‚  â”‚ Limpieza â”‚  â”‚   KPIs   â”‚  â”‚  Final   â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“              â†“              â†“              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     DATA STORAGE (Filesystem)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  Bronze  â”‚  â”‚  Silver  â”‚  â”‚        Gold          â”‚          â”‚
â”‚  â”‚  /data   â”‚  â”‚  /data   â”‚  â”‚       /data          â”‚          â”‚
â”‚  â”‚  /bronze â”‚  â”‚  /silver â”‚  â”‚       /gold          â”‚          â”‚
â”‚  â”‚          â”‚  â”‚          â”‚  â”‚  â”œâ”€ kpi_stats.csv   â”‚          â”‚
â”‚  â”‚  raw.csv â”‚  â”‚clean.csv â”‚  â”‚  â”œâ”€ kpi_cat.csv     â”‚          â”‚
â”‚  â”‚          â”‚  â”‚          â”‚  â”‚  â”œâ”€ kpi_top5.csv    â”‚          â”‚
â”‚  â”‚          â”‚  â”‚          â”‚  â”‚  â”œâ”€ kpi_dist.csv    â”‚          â”‚
â”‚  â”‚          â”‚  â”‚          â”‚  â”‚  â””â”€ kpi_ritmo.csv   â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### DescripciÃ³n de Capas

#### ğŸ¥‰ Capa Bronze (Raw / Landing Zone)

**PropÃ³sito**: Almacenar datos exactamente como llegan de la fuente.

**CaracterÃ­sticas**:
- âœ… Sin transformaciones
- âœ… Inmutable (append-only)
- âœ… Sirve como backup y punto de re-procesamiento
- âœ… Formato: CSV sin validaciÃ³n

**Output**: `data/bronze/resultados_raw.csv`

**Principio**: *"Preserve la fuente de verdad"*

---

#### ğŸ¥ˆ Capa Silver (Cleansed / Conformed)

**PropÃ³sito**: Datos limpios, validados y listos para anÃ¡lisis.

**Transformaciones Aplicadas**:
1. **Parsing de campos concatenados**
   ```python
   "Varones 30 a 39 aÃ±osdorsal: 2395"
   â†“
   genero: "Varones"
   rango_edad: "30 a 39 aÃ±os"
   dorsal: 2395
   ```

2. **Limpieza de formatos**
   ```python
   "127Âº" â†’ 127 (integer)
   "1:46:32" â†’ 6392 (segundos)
   ```

3. **NormalizaciÃ³n de nombres**
   ```python
   "alexandrina vivar diaz" â†’ "Alexandrina Vivar Diaz"
   ```

4. **Enriquecimiento con mÃ©tricas calculadas**
   ```python
   tiempo_segundos â†’ ritmo_min_km, velocidad_kmh
   ```

**Output**: `data/silver/resultados_clean.csv`

**Principio**: *"Una sola versiÃ³n de la verdad, limpia y estructurada"*

---

#### ğŸ¥‡ Capa Gold (Curated / Business-Ready)

**PropÃ³sito**: Datos agregados y optimizados para consumo de negocio/anÃ¡lisis.

**KPIs Generados**:

| Archivo | DescripciÃ³n | Uso |
|---------|-------------|-----|
| `kpi_estadisticas_generales.csv` | MÃ©tricas globales de la carrera | Dashboards ejecutivos |
| `kpi_tiempo_por_categoria.csv` | Promedios por categorÃ­a | AnÃ¡lisis comparativo |
| `kpi_top5_por_genero.csv` | Rankings por gÃ©nero | Premiaciones, prensa |
| `kpi_distribucion_edad.csv` | DemografÃ­a de participantes | Marketing, planeaciÃ³n |
| `kpi_top10_ritmo.csv` | Mejores ritmos overall | AnÃ¡lisis de Ã©lite |

**Principio**: *"Datos listos para decisiones, sin procesamiento adicional"*

---

### Componentes de Infraestructura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DOCKER COMPOSE                           â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   PostgreSQL   â”‚  â”‚    Airflow     â”‚  â”‚   Airflow    â”‚ â”‚
â”‚  â”‚   (Metadata)   â”‚  â”‚   Scheduler    â”‚  â”‚  Webserver   â”‚ â”‚
â”‚  â”‚                â”‚  â”‚                â”‚  â”‚              â”‚ â”‚
â”‚  â”‚  Puerto: 5432  â”‚  â”‚  - Ejecuta     â”‚  â”‚ Puerto: 8081 â”‚ â”‚
â”‚  â”‚                â”‚  â”‚    tareas      â”‚  â”‚ (UI Web)     â”‚ â”‚
â”‚  â”‚  - Historial   â”‚  â”‚  - Gestiona    â”‚  â”‚              â”‚ â”‚
â”‚  â”‚    de DAG runs â”‚  â”‚    dependenciasâ”‚  â”‚ - Monitoreo  â”‚ â”‚
â”‚  â”‚  - Conexiones  â”‚  â”‚  - Reintentos  â”‚  â”‚ - EjecuciÃ³n  â”‚ â”‚
â”‚  â”‚  - Variables   â”‚  â”‚                â”‚  â”‚   manual     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â†‘                    â†‘                    â†‘        â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                    Red interna Docker                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  VolÃºmenes       â”‚
                    â”‚  Montados        â”‚
                    â”‚                  â”‚
                    â”‚  ./dags     â†’    â”‚
                    â”‚  ./scripts  â†’    â”‚
                    â”‚  ./data     â†’    â”‚
                    â”‚  ./logs     â†’    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Flujo de los Datos

### Diagrama de Flujo Completo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ INICIO: Usuario ejecuta DAG desde Airflow UI                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TAREA 1: bronze_ingesta                                         â”‚
â”‚                                                                 â”‚
â”‚ FunciÃ³n: process_bronze()                                       â”‚
â”‚ Archivo: scripts/pipeline_tasks.py                             â”‚
â”‚                                                                 â”‚
â”‚ Proceso:                                                        â”‚
â”‚ 1. Crear directorio /data/bronze/ si no existe                 â”‚
â”‚ 2. Generar datos simulados (25 registros)                      â”‚
â”‚ 3. Crear DataFrame de Pandas con columnas raw                  â”‚
â”‚ 4. Guardar como CSV sin transformaciones                       â”‚
â”‚                                                                 â”‚
â”‚ Input:  Ninguno (datos simulados)                              â”‚
â”‚ Output: /data/bronze/resultados_raw.csv                        â”‚
â”‚ Tiempo: ~1-2 segundos                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TAREA 2: silver_limpieza                                        â”‚
â”‚                                                                 â”‚
â”‚ FunciÃ³n: process_silver(bronze_file)                            â”‚
â”‚ Archivo: scripts/pipeline_tasks.py                             â”‚
â”‚                                                                 â”‚
â”‚ Proceso:                                                        â”‚
â”‚ 1. Leer CSV de Bronze con pd.read_csv()                        â”‚
â”‚ 2. Aplicar regex a 'categoria_dorsal':                         â”‚
â”‚    Pattern: ^(Varones|Damas)\s+(.+?)dorsal:\s*(\d+)$          â”‚
â”‚    â†’ Extraer: genero, rango_edad, dorsal                       â”‚
â”‚ 3. Limpiar posiciones (remover 'Âº', cast a int)                â”‚
â”‚ 4. Normalizar nombres con .str.title()                         â”‚
â”‚ 5. Calcular mÃ©tricas:                                           â”‚
â”‚    - tiempo_segundos = H*3600 + M*60 + S                       â”‚
â”‚    - ritmo_min_km = tiempo / 21.1 km                            â”‚
â”‚    - velocidad_kmh = 21.1 / (tiempo/3600)                      â”‚
â”‚ 6. Reordenar columnas para legibilidad                         â”‚
â”‚ 7. Guardar CSV limpio                                           â”‚
â”‚                                                                 â”‚
â”‚ Input:  /data/bronze/resultados_raw.csv                        â”‚
â”‚ Output: /data/silver/resultados_clean.csv                      â”‚
â”‚ Tiempo: ~2-3 segundos                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TAREA 3: gold_kpis                                              â”‚
â”‚                                                                 â”‚
â”‚ FunciÃ³n: process_gold(silver_file)                              â”‚
â”‚ Archivo: scripts/pipeline_tasks.py                             â”‚
â”‚                                                                 â”‚
â”‚ Proceso:                                                        â”‚
â”‚ 1. Leer CSV de Silver                                           â”‚
â”‚ 2. Generar 5 KPIs:                                              â”‚
â”‚                                                                 â”‚
â”‚    KPI 1: EstadÃ­sticas Generales                               â”‚
â”‚    - Total participantes, varones, damas                        â”‚
â”‚    - Tiempos: ganador, Ãºltimo, promedio                        â”‚
â”‚    - MÃ©tricas: ritmo promedio, velocidad promedio              â”‚
â”‚                                                                 â”‚
â”‚    KPI 2: Tiempo por CategorÃ­a                                 â”‚
â”‚    - GROUP BY categoria                                         â”‚
â”‚    - AGG: mean, min, max, count de tiempo_segundos             â”‚
â”‚                                                                 â”‚
â”‚    KPI 3: Top 5 por GÃ©nero                                     â”‚
â”‚    - FILTER por genero                                          â”‚
â”‚    - SORT BY tiempo_segundos ASC                               â”‚
â”‚    - LIMIT 5                                                    â”‚
â”‚                                                                 â”‚
â”‚    KPI 4: DistribuciÃ³n por Edad                                â”‚
â”‚    - GROUP BY rango_edad, genero                               â”‚
â”‚    - COUNT + calcular porcentaje                               â”‚
â”‚                                                                 â”‚
â”‚    KPI 5: Top 10 Ritmos                                        â”‚
â”‚    - SORT BY tiempo_segundos ASC                               â”‚
â”‚    - LIMIT 10                                                   â”‚
â”‚                                                                 â”‚
â”‚ Input:  /data/silver/resultados_clean.csv                      â”‚
â”‚ Output: 5 archivos CSV en /data/gold/                          â”‚
â”‚ Tiempo: ~2-3 segundos                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TAREA 4: validacion_final                                      â”‚
â”‚                                                                 â”‚
â”‚ FunciÃ³n: validacion_task(gold_outputs)                          â”‚
â”‚ Archivo: dags/media_maraton_dag.py                             â”‚
â”‚                                                                 â”‚
â”‚ Proceso:                                                        â”‚
â”‚ 1. Recibir diccionario con rutas de archivos Gold              â”‚
â”‚ 2. Verificar existencia de cada archivo con Path.exists()      â”‚
â”‚ 3. Contar archivos vÃ¡lidos vs esperados                        â”‚
â”‚ 4. Generar mensaje de resumen                                  â”‚
â”‚ 5. Loguear resultado final                                     â”‚
â”‚                                                                 â”‚
â”‚ Input:  Dict con rutas de archivos Gold                        â”‚
â”‚ Output: Mensaje de validaciÃ³n (string)                         â”‚
â”‚ Tiempo: <1 segundo                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FIN: Pipeline completado exitosamente                          â”‚
â”‚                                                                 â”‚
â”‚ Resultado:                                                      â”‚
â”‚ âœ… 1 archivo Bronze                                             â”‚
â”‚ âœ… 1 archivo Silver                                             â”‚
â”‚ âœ… 5 archivos Gold                                              â”‚
â”‚ âœ… Logs detallados en /logs/                                    â”‚
â”‚                                                                 â”‚
â”‚ Tiempo total: ~4-8 minutos (incluye overhead de Airflow)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flujo de Dependencias en Airflow

```python
# RepresentaciÃ³n en cÃ³digo del flujo
bronze_output = bronze_task()                    # Paso 1
silver_output = silver_task(bronze_output)       # Paso 2 (depende de 1)
gold_outputs = gold_task(silver_output)          # Paso 3 (depende de 2)
validacion_task(gold_outputs)                    # Paso 4 (depende de 3)
```

**VisualizaciÃ³n en Airflow UI:**

```
bronze_ingesta â”€â”€â†’ silver_limpieza â”€â”€â†’ gold_kpis â”€â”€â†’ validacion_final
     ğŸŸ¢                  ğŸŸ¢                ğŸŸ¢              ğŸŸ¢
```

---

## âœ… Calidad de los Datos

### Framework de Data Quality

Este proyecto implementa mÃºltiples capas de validaciÃ³n para garantizar la calidad de los datos en cada etapa del pipeline.

### 1. Validaciones en Capa Bronze

#### âœ… Completitud
- **Check**: Todos los registros tienen los 5 campos requeridos
- **ImplementaciÃ³n**: ValidaciÃ³n automÃ¡tica de Pandas al crear DataFrame
- **AcciÃ³n en fallo**: ExcepciÃ³n que detiene el pipeline

```python
# ValidaciÃ³n implÃ­cita
required_columns = ["pos_general", "pos_categoria", "nombre_corredor", 
                   "categoria_dorsal", "tiempo_oficial"]
```

#### âœ… Formato de Archivo
- **Check**: El archivo se puede leer como CSV vÃ¡lido
- **ImplementaciÃ³n**: Try-catch en proceso de lectura
- **AcciÃ³n en fallo**: Log de error + reintento (configurado en Airflow)

---

### 2. Validaciones en Capa Silver

#### âœ… Parsing de Regex
- **Check**: El campo `categoria_dorsal` se puede parsear correctamente
- **ImplementaciÃ³n**: 
  ```python
  pattern = r'^(Varones|Damas)\s+(.+?)dorsal:\s*(\d+)$'
  if not match:
      logger.warning(f"No se pudo parsear: {texto}")
      return "Desconocido", "Desconocido", texto, None
  ```
- **Tolerancia**: Registros invÃ¡lidos se marcan como "Desconocido" pero no detienen el pipeline
- **Trazabilidad**: Warnings logueados para auditorÃ­a

#### âœ… Tipos de Datos
- **Checks implementados**:
  - `pos_general`, `pos_categoria`: Convertibles a integer
  - `dorsal`: Integer positivo
  - `tiempo_segundos`: Integer positivo
  - `velocidad_kmh`: Float positivo y realista (<30 km/h)

```python
# ValidaciÃ³n de tipos
df['pos_general'] = df['pos_general'].str.replace('Âº', '').astype(int)
df['tiempo_segundos'] = df['tiempo_oficial'].apply(_tiempo_a_segundos)
```

#### âœ… Rangos VÃ¡lidos
| Campo | ValidaciÃ³n | Rango Esperado |
|-------|-----------|----------------|
| `pos_general` | > 0 | 1 - 1000 |
| `tiempo_segundos` | > 0 | 3600 - 18000 (1h - 5h) |
| `velocidad_kmh` | > 0 y < 30 | 4.0 - 25.0 km/h |
| `ritmo_min_km` | Formato M:SS | 2:30 - 15:00 |

#### âœ… Unicidad
- **Check**: No hay dorsales duplicados
- **ImplementaciÃ³n**: 
  ```python
  duplicados = df['dorsal'].duplicated().sum()
  if duplicados > 0:
      logger.warning(f"âš ï¸ {duplicados} dorsales duplicados encontrados")
  ```
- **AcciÃ³n**: Warning logueado, anÃ¡lisis manual requerido

#### âœ… Consistencia Referencial
- **Check**: Las categorÃ­as extraÃ­das coinciden con valores esperados
- **CategorÃ­as vÃ¡lidas**: 
  - Varones: 18-29, 30-39, 40-49, 50-59, 60+
  - Damas: 18-29, 30-39, 40-49, 50-59, 60+

---

### 3. Validaciones en Capa Gold

#### âœ… Integridad de Agregaciones
- **Check**: Los totales en KPIs suman correctamente
- **Ejemplo**: 
  ```python
  total_participantes = len(df)
  suma_categorias = df_por_categoria['cantidad_corredores'].sum()
  assert total_participantes == suma_categorias
  ```

#### âœ… MÃ©tricas Calculadas
- **Checks**:
  - Tiempo promedio estÃ¡ entre el mÃ­nimo y mÃ¡ximo observado
  - Los rankings no tienen gaps (1, 2, 3... sin saltos)
  - Porcentajes suman 100%

#### âœ… Completitud de Outputs
- **Check**: Se generaron los 5 archivos KPI esperados
- **ImplementaciÃ³n**: Tarea `validacion_final`
  ```python
  archivos_esperados = 5
  archivos_generados = len([f for f in gold_outputs.values() if Path(f).exists()])
  if archivos_generados != archivos_esperados:
      logger.error(f"Faltan {archivos_esperados - archivos_generados} archivos")
  ```

---

### 4. Calidad del CÃ³digo

#### âœ… Logging Estructurado
Todos los procesos incluyen logs en 3 niveles:

```python
logger.info("ğŸ¥‰ Iniciando proceso BRONZE")    # Inicio de proceso
logger.warning("âš ï¸ No se pudo parsear: X")    # AnomalÃ­as no crÃ­ticas
logger.error("âŒ Error en Bronze: X")         # Errores que detienen ejecuciÃ³n
```

#### âœ… Manejo de Errores
- **Try-Catch en todas las funciones principales**
- **Re-raise de excepciones** para que Airflow las capture
- **Mensajes descriptivos** con contexto del error

```python
try:
    df = pd.read_csv(input_file)
except FileNotFoundError:
    logger.error(f"âŒ Archivo no encontrado: {input_file}")
    raise
except Exception as e:
    logger.error(f"âŒ Error inesperado: {str(e)}")
    raise
```

#### âœ… Type Hints
```python
def process_bronze() -> str:
    """Retorna la ruta del archivo creado"""
    
def _parse_categoria_dorsal(texto: str) -> tuple[str, str, str, Optional[int]]:
    """Retorna tupla con valores parseados"""
```

---

### 5. Monitoreo de Calidad en Airflow

#### Dashboard de MÃ©tricas

La UI de Airflow proporciona:

| MÃ©trica | DescripciÃ³n | Umbral de Alerta |
|---------|-------------|------------------|
| **Success Rate** | % de ejecuciones exitosas | < 95% |
| **Duration** | Tiempo de ejecuciÃ³n | > 10 minutos |
| **Task Failures** | Fallos por tarea | > 0 en producciÃ³n |
| **Data Volume** | Registros procesados | VariaciÃ³n > 20% |

#### Alertas Configurables

```python
default_args = {
    'email_on_failure': True,           # Email si falla
    'email_on_retry': False,            # No email en retry
    'retries': 2,                       # Reintentar 2 veces
    'retry_delay': timedelta(minutes=2) # Esperar 2 min entre reintentos
}
```

---

### 6. Matriz de Calidad de Datos

| DimensiÃ³n | Bronze | Silver | Gold | Herramienta |
|-----------|--------|--------|------|-------------|
| **Completitud** | âš ï¸ Parcial | âœ… 100% | âœ… 100% | Pandas assertions |
| **Validez** | âŒ Sin validar | âœ… Regex + tipos | âœ… Validado | Python validations |
| **PrecisiÃ³n** | âŒ Raw | âœ… Normalizado | âœ… Agregado | CÃ¡lculos verificados |
| **Consistencia** | âŒ Inconsistente | âœ… Estandarizado | âœ… Coherente | Business rules |
| **Unicidad** | âš ï¸ No verificada | âœ… Verificada | N/A | Duplicate checks |
| **Integridad** | âŒ No aplicable | âœ… Referencias OK | âœ… Totales OK | Referential checks |

**Leyenda:**
- âœ… Validado y garantizado
- âš ï¸ Parcialmente validado
- âŒ No validado (by design en Bronze)

---

### 7. Tests de Calidad (Futuros)

**Roadmap de Testing:**

```python
# tests/test_silver_quality.py
def test_no_null_dorsales():
    df = pd.read_csv('data/silver/resultados_clean.csv')
    assert df['dorsal'].isnull().sum() == 0

def test_tiempo_segundos_positive():
    df = pd.read_csv('data/silver/resultados_clean.csv')
    assert (df['tiempo_segundos'] > 0).all()

def test_velocidad_realista():
    df = pd.read_csv('data/silver/resultados_clean.csv')
    assert (df['velocidad_kmh'] > 4).all()
    assert (df['velocidad_kmh'] < 30).all()
```

---

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### Prerequisitos

- **Docker Desktop** 20.10+
- **Docker Compose** 2.0+
- **RAM disponible:** MÃ­nimo 4GB (recomendado 6GB)
- **Espacio en disco:** ~2GB para imÃ¡genes Docker
- **Sistema operativo:** Windows 10/11, macOS, o Linux

### InstalaciÃ³n Paso a Paso

#### 1. Clonar o Descargar el Proyecto

```bash
# OpciÃ³n A: Con Git
git clone https://github.com/MRiveraV24/Proyecto_06_media_maraton_ETL_pipeline.git
cd Proyecto_06_media_maraton_ETL_pipeline

# OpciÃ³n B: Descarga manual
# Descarga el ZIP y extrae en tu carpeta de proyectos
```

#### 2. Verificar la Estructura

```bash
dir  # En Windows
ls   # En Linux/Mac

# Debes ver:
# dags/
# scripts/
# data/
# logs/
# docker-compose.yaml
# Dockerfile
# requirements.txt
```

#### 3. Construir las ImÃ¡genes

```bash
docker compose build
```

**Tiempo estimado:** 3-5 minutos la primera vez.

#### 4. Levantar los Servicios

```bash
docker compose up -d
```

#### 5. Esperar InicializaciÃ³n

```bash
# Esperar 60-90 segundos
# Verificar estado
docker compose ps
```

Todos los servicios deben mostrar `Up` o `Up (healthy)`.

#### 6. Acceder a Airflow

Abre en tu navegador: **http://localhost:8081**

**Credenciales:**
- Usuario: `admin`
- Password: `admin`

---

## ğŸ® Uso del Pipeline

### EjecuciÃ³n Manual (Primera Vez)

1. **Activar el DAG**
   - En la UI de Airflow, busca `pipeline_media_maraton_la_serena_2024`
   - Haz clic en el toggle para activarlo (de gris a verde)

2. **Ejecutar**
   - Haz clic en el botÃ³n â–¶ï¸ (Play)
   - Selecciona "Trigger DAG"

3. **Monitorear**
   - Observa las tareas cambiar de color:
     - â¬œ En cola
     - ğŸŸ¡ Ejecutando
     - ğŸŸ¢ Ã‰xito
     - ğŸ”´ Error

4. **Verificar Resultados**
   ```bash
   # Ver archivos generados
   dir data\bronze
   dir data\silver
   dir data\gold
   ```

### EjecuciÃ³n Programada (Opcional)

Para ejecutar automÃ¡ticamente cada dÃ­a:

```python
# En dags/media_maraton_dag.py
@dag(
    schedule='@daily',  # Cambia de None a '@daily'
    start_date=datetime(2024, 11, 23),
    catchup=False,
)
```

**Opciones de schedule:**
- `'@hourly'` - Cada hora
- `'@daily'` - Cada dÃ­a a medianoche
- `'0 6 * * *'` - Cada dÃ­a a las 6 AM
- `'0 */4 * * *'` - Cada 4 horas

---

## ğŸ“ Estructura del Proyecto

```
media_maraton_pipeline/
â”‚
â”œâ”€â”€ dags/                        # DAGs de Airflow
â”‚   â””â”€â”€ media_maraton_dag.py     # DAG principal del pipeline
â”‚
â”œâ”€â”€ scripts/                     # LÃ³gica de negocio
â”‚   â”œâ”€â”€ __init__.py              # Inicializador de paquete
â”‚   â””â”€â”€ pipeline_tasks.py        # Funciones Bronze/Silver/Gold
â”‚
â”œâ”€â”€ data/                          # Datos organizados por capa
â”‚   â”œâ”€â”€ bronze/                   # Capa raw
â”‚   â”‚   â””â”€â”€ resultados_raw.csv    # Datos crudos (generado)
â”‚   â”œâ”€â”€ silver/                   # Capa limpia
â”‚   â”‚   â””â”€â”€ resultados_clean.csv  # Datos transformados (generado)
â”‚   â””â”€â”€ gold/                     # Capa de KPIs
â”‚       â”œâ”€â”€ kpi_estadisticas_generales.csv
â”‚       â”œâ”€â”€ kpi_tiempo_por_categoria.csv
â”‚       â”œâ”€â”€ kpi_top5_por_genero.csv
â”‚       â”œâ”€â”€ kpi_distribucion_edad.csv
â”‚       â””â”€â”€ kpi_top10_ritmo.csv
â”‚
â”œâ”€â”€ logs/                       # Logs de Airflow (auto-generado)
â”œâ”€â”€ docker-compose.yaml         # OrquestaciÃ³n de contenedores
â”œâ”€â”€ Dockerfile                  # Imagen personalizada  de Airflow
â”œâ”€â”€ requirements.txt            # Dependencias Python
â””â”€â”€ README.md                   # Este archivo
```
---

## ğŸ“Š KPIs Generados

### 1. EstadÃ­sticas Generales (`kpi_estadisticas_generales.csv`)

**Contenido:**
```csv
total_participantes,total_varones,total_damas,tiempo_ganador,tiempo_ultimo,tiempo_promedio_segundos,ritmo_promedio,velocidad_promedio_kmh,fecha_proceso
25,17,8,1:12:45,2:30:15,6660.0,5:16,11.38,2024-11-23T22:49:16
```

**Uso:** Dashboard ejecutivo, reportes de prensa

---

### 2. Tiempo por CategorÃ­a (`kpi_tiempo_por_categoria.csv`)

**Contenido:**
```csv
categoria,tiempo_promedio_seg,tiempo_mejor_seg,tiempo_peor_seg,cantidad_corredores,velocidad_promedio_kmh,ritmo_promedio
Varones 18 a 29 aÃ±os,4226.5,4365,4088,2,17.98,3:20
Varones 30 a 39 aÃ±os,5643.17,5522,6392,6,13.45,4:27
...
```

**Uso:** AnÃ¡lisis comparativo entre categorÃ­as

---

### 3. Top 5 por GÃ©nero (`kpi_top5_por_genero.csv`)

**Contenido:**
```csv
pos_general,nombre_corredor,categoria,tiempo_oficial,ritmo_min_km,ranking_genero,genero
1,Carlos AndrÃ©s DÃ­az Moreno,Varones 18 a 29 aÃ±os,1:12:45,3:26,1,Varones
2,Miguel Ãngel Torres,Varones 30 a 39 aÃ±os,1:15:22,3:34,2,Varones
...
5,Andrea Paz GonzÃ¡lez,Damas 18 a 29 aÃ±os,1:19:45,3:46,1,Damas
...
```

**Uso:** Premiaciones, comunicados de prensa

---

### 4. DistribuciÃ³n por Edad (`kpi_distribucion_edad.csv`)

**Contenido:**
```csv
rango_edad,genero,cantidad,porcentaje
18 a 29 aÃ±os,Varones,2,8.0
18 a 29 aÃ±os,Damas,2,8.0
30 a 39 aÃ±os,Varones,6,24.0
...
```

**Uso:** Marketing, planeaciÃ³n de futuras ediciones

---

### 5. Top 10 Ritmos (`kpi_top10_ritmo.csv`)

**Contenido:**
```csv
pos_general,dorsal,nombre_corredor,categoria,tiempo_oficial,ritmo_min_km,velocidad_kmh
1,2001,Carlos AndrÃ©s DÃ­az Moreno,Varones 18 a 29 aÃ±os,1:12:45,3:26,17.43
2,2102,Miguel Ãngel Torres,Varones 30 a 39 aÃ±os,1:15:22,3:34,16.82
...
```

**Uso:** AnÃ¡lisis de Ã©lite, identificaciÃ³n de talentos

---

## ğŸ“ˆ Monitoreo y Logs

### VisualizaciÃ³n en Airflow UI

#### Vista de Grid
- Muestra historial de ejecuciones
- Estados por tarea con cÃ³digo de colores
- DuraciÃ³n de cada run

#### Vista de Graph
- Diagrama visual de dependencias
- Estado en tiempo real de cada tarea
- Camino crÃ­tico resaltado

#### Vista de Gantt
- Timeline de ejecuciÃ³n
- IdentificaciÃ³n de cuellos de botella
- ParalelizaciÃ³n de tareas (si aplica)

### Logs Detallados

#### Acceso a Logs por Tarea

1. Click en el cuadro de una tarea (ej: `bronze_ingesta`)
2. Click en "Log"
3. Ver output completo con timestamps

**Ejemplo de logs exitosos:**

```
[2024-11-23, 22:49:16] INFO - ğŸ¥‰ Iniciando proceso BRONZE - Ingesta de datos crudos
[2024-11-23, 22:49:16] INFO - âœ… Bronze completado: 25 registros guardados en /opt/airflow/data/bronze/resultados_raw.csv
```
#### ğŸ“¸ Captura Real de la Vista Graph del Pipeline 

![Graph](dags/Airflow_graph.png)

#### Logs desde CLI

```bash
# Ver logs de todas las tareas
docker compose logs airflow-scheduler

# Ver logs en tiempo real
docker compose logs -f airflow-scheduler

# Filtrar por palabra clave
docker compose logs airflow-scheduler | findstr "ERROR"
```

---

## ğŸ› ï¸ Troubleshooting

### Problema: "DAG no aparece en la UI"

**SoluciÃ³n:**
```bash
# 1. Verificar que el archivo existe
docker compose exec airflow-scheduler ls /opt/airflow/dags/

# 2. Buscar errores de sintaxis
docker compose exec airflow-scheduler python /opt/airflow/dags/media_maraton_dag.py

# 3. Reiniciar scheduler
docker compose restart airflow-scheduler

# 4. Esperar 30 segundos y refrescar navegador
```

---

### Problema: "Task failed with ModuleNotFoundError"

**SoluciÃ³n:**
```bash
# Verificar que scripts estÃ¡ montado
docker compose exec airflow-scheduler ls -la /opt/airflow/scripts/

# Debe mostrar __init__.py y pipeline_tasks.py
# Si no, verifica docker-compose.yaml secciÃ³n volumes
```

---

### Problema: "Cannot connect to Docker daemon"

**SoluciÃ³n:**
1. Abrir Docker Desktop
2. Esperar a que el Ã­cono estÃ© en verde
3. Reintentar `docker compose up -d`

---

### Problema: "Port 8081 already in use"

**SoluciÃ³n:**
```bash
# OpciÃ³n A: Cambiar puerto en docker-compose.yaml
# ports:
#   - "8082:8080"

# OpciÃ³n B: Liberar puerto 8081
netstat -ano | findstr :8081
taskkill /PID [nÃºmero] /F
```

---

## ğŸ—ºï¸ Roadmap

### VersiÃ³n 1.1 (Planificado)

- [ ] Conectar a API real de resultados de carreras
- [ ] Implementar tests unitarios con pytest
- [ ] Agregar pre-commit hooks para calidad de cÃ³digo
- [ ] Documentar APIs con Sphinx

### VersiÃ³n 1.2 (Futuro)

- [ ] Dashboard interactivo con Streamlit/Plotly
- [ ] Alertas por Slack/Email configurables
- [ ] IntegraciÃ³n con Great Expectations para data quality
- [ ] Exportar KPIs a base de datos (PostgreSQL/MySQL)

### VersiÃ³n 2.0 (VisiÃ³n)

- [ ] MigraciÃ³n a cloud (AWS MWAA, GCP Composer, o Azure Data Factory)
- [ ] Data lake con S3/GCS
- [ ] CI/CD con GitHub Actions
- [ ] MLOps: PredicciÃ³n de tiempos con ML

---

## ğŸ‘¥ Contribuciones

### Â¿CÃ³mo Contribuir?

1. **Fork** el repositorio
2. Crea una **rama** para tu feature (`git checkout -b feature/nueva-funcionalidad`)
3. **Commit** tus cambios (`git commit -m 'feat: Agregar nuevo KPI de velocidad'`)
4. **Push** a la rama (`git push origin feature/nueva-funcionalidad`)
5. Abre un **Pull Request**

### EstÃ¡ndares de CÃ³digo

- Seguir **PEP 8** para Python
- Documentar funciones con **docstrings**
- Agregar **type hints** en firmas de funciones
- Incluir **logs** en procesos importantes
- Escribir **tests** para nuevas features

---

## ğŸ“œ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver archivo [LICENSE](LICENSE) para mÃ¡s detalles.

```
MIT License

Copyright (c) 2024 [Tu Nombre]

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction...
```

---

## ğŸ“§ Contacto

**Autor:** Marcelo Rivera Vega,Data Engineering

- **GitHub:**   [MRiveraV24](https://github.com/MRiveraV24)
- **LinkedIn:** [marcelo-rivera-vega](https://linkedin.com/in/marcelo-rivera-vega)
- **Email:**    marcelo.rivera.vega@gmail.com

---

## ğŸ™ Agradecimientos

- **Apache Airflow Community** por la excelente documentaciÃ³n
- **Databricks** por popularizar la arquitectura Medallion
- **Organizadores de la Media MaratÃ³n La Serena** por la inspiraciÃ³n
- **Comunidad de Data Engineering** por compartir conocimiento

---

## ğŸ“š Referencias y Recursos

### DocumentaciÃ³n Oficial

- [Apache Airflow Docs](https://airflow.apache.org/docs/)
- [Pandas Documentation](https://pandas.pydata.org/docs/)
- [Docker Compose Reference](https://docs.docker.com/compose/)

### Tutoriales y GuÃ­as

- [Medallion Architecture](https://www.databricks.com/glossary/medallion-architecture)
- [Data Engineering Best Practices](https://github.com/DataTalksClub/data-engineering-zoomcamp)
- [Airflow TaskFlow API](https://airflow.apache.org/docs/apache-airflow/stable/tutorial/taskflow.html)

### Herramientas Complementarias

- [Great Expectations](https://greatexpectations.io/) - Data Quality
- [dbt](https://www.getdbt.com/) - Data Transformation
- [Metabase](https://www.metabase.com/) - Business Intelligence

---

## ğŸ“Š MÃ©tricas del Proyecto

| MÃ©trica | Valor |
|---------|-------|
| **LÃ­neas de cÃ³digo** | ~800 (Python) |
| **Cobertura de tests** | 0% (Roadmap v1.1) |
| **Tiempo de ejecuciÃ³n** | ~4-8 minutos |
| **Datos procesados** | 25 registros (demo) |
| **Archivos generados** | 7 CSVs (1 Bronze, 1 Silver, 5 Gold) |
| **Ãšltima actualizaciÃ³n** | 2024-11-23 |

---

## ğŸ¯ Casos de Uso

### Para Analistas de Datos
- Aprender ingenierÃ­a de datos con un proyecto realista
- Entender arquitecturas de datos modernas
- Practicar transformaciones con Pandas

### Para Organizadores de Eventos
- Automatizar procesamiento de resultados
- Generar reportes instantÃ¡neos
- Reducir errores humanos en anÃ¡lisis

### Para Empresas Deportivas
- Benchmarking de rendimiento
- AnÃ¡lisis demogrÃ¡fico de participantes
- IdentificaciÃ³n de tendencias

---

**â­ Si este proyecto te fue Ãºtil, considera darle una estrella en GitHub!**

**ğŸ’¬ Â¿Preguntas o sugerencias? Abre un [Issue](https://github.com/MRiveraV24/Proyecto_06_media_maraton_ETL_pipeline/issues)**

---

*Ãšltima actualizaciÃ³n: 2024-11-23 | VersiÃ³n 1.0*
