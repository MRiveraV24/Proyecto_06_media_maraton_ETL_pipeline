# ğŸƒ Pipeline Analytics - Media MaratÃ³n La Serena 2024

[![Apache Airflow](https://img.shields.io/badge/Apache%20Airflow-2.8.1-017CEE?logo=apache-airflow)](https://airflow.apache.org/)
[![Python](https://img.shields.io/badge/Python-3.11-3776AB?logo=python)](https://python.org/)
[![Docker](https://img.shields.io/badge/Docker-Compose-2496ED?logo=docker)](https://docker.com/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## ğŸ“– DescripciÃ³n

Pipeline de datos **end-to-end** para procesar y analizar los resultados de la Media MaratÃ³n La Serena 2024. Este proyecto implementa la **Arquitectura MedallÃ³n** (Bronze-Silver-Gold) orquestada con **Apache Airflow** y containerizada con **Docker**.

--

## ğŸ¯ Problema que Resuelve

Los datos de carreras suelen venir en formatos "sucios":
- Campos concatenados (`"Varones 30 a 39 aÃ±osdorsal: 2395"`)
- Formatos inconsistentes de tiempo
- Nombres mal capitalizados
- Sin mÃ©tricas calculadas

Este pipeline automatiza la limpieza y genera **KPIs listos para anÃ¡lisis**.

---

## ğŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    BRONZE    â”‚â”€â”€â”€â”€â–¶â”‚    SILVER    â”‚â”€â”€â”€â”€â–¶â”‚     GOLD     â”‚â”€â”€â”€â”€â–¶â”‚  VALIDACIÃ“N  â”‚
â”‚   Ingesta    â”‚     â”‚   Limpieza   â”‚     â”‚     KPIs     â”‚     â”‚    Final     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                    â”‚                    â”‚
      â–¼                    â–¼                    â–¼
  CSV crudo           Datos limpios      5 archivos de KPIs
  25 registros        + mÃ©tricas         para dashboards
```

### Capas del Pipeline

| Capa | Input | Output | DescripciÃ³n |
|------|-------|--------|-------------|
| **Bronze** | SimulaciÃ³n | `resultados_raw.csv` | Datos crudos tal como vienen de la fuente |
| **Silver** | Bronze CSV | `resultados_clean.csv` | Datos limpios, tipados, con mÃ©tricas calculadas |
| **Gold** | Silver CSV | 5 archivos de KPIs | Agregaciones listas para consumo de negocio |

---

## ğŸ“Š KPIs Generados (Capa Gold)

1. **`kpi_estadisticas_generales.csv`** - Resumen de la carrera
2. **`kpi_tiempo_por_categoria.csv`** - Promedios por categorÃ­a
3. **`kpi_top5_por_genero.csv`** - Mejores 5 varones y damas
4. **`kpi_distribucion_edad.csv`** - Participantes por rango de edad
5. **`kpi_top10_ritmo.csv`** - Los 10 corredores mÃ¡s rÃ¡pidos

---

## ğŸš€ Inicio RÃ¡pido

### Prerrequisitos

- [Docker Desktop](https://www.docker.com/products/docker-desktop/) instalado
- [Git](https://git-scm.com/) (opcional)
- 4GB RAM mÃ­nimo disponible

### Paso 1: Clonar/Crear el proyecto

```bash
# Crear estructura de carpetas
mkdir -p media_maraton_pipeline/{dags,scripts,data/{bronze,silver,gold},logs}
cd media_maraton_pipeline

# Crear archivo __init__.py
touch scripts/__init__.py
```

### Paso 2: Crear los archivos

Copia el contenido de los siguientes archivos del tutorial:
- `docker-compose.yaml`
- `Dockerfile`
- `requirements.txt`
- `dags/media_maraton_dag.py`
- `scripts/pipeline_tasks.py`

### Paso 3: Levantar el entorno

```bash
# Construir la imagen (solo la primera vez o si cambias requirements.txt)
docker compose build

# Levantar todos los servicios
docker compose up -d

# Verificar que todo estÃ© corriendo
docker compose ps
```

### Paso 4: Acceder a Airflow

1. Abre tu navegador en **http://localhost:8080**
2. Login: `admin` / `admin`
3. Busca el DAG: `pipeline_media_maraton_la_serena_2024`
4. ActÃ­valo con el toggle (ON)
5. Haz clic en **"Trigger DAG"** â–¶ï¸

### Paso 5: Verificar resultados

```bash
# Ver los archivos generados
ls -la data/bronze/
ls -la data/silver/
ls -la data/gold/

# Ver contenido de un KPI
cat data/gold/kpi_estadisticas_generales.csv
```

---

## ğŸ“ Estructura del Proyecto

```
media_maraton_pipeline/
â”‚
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ media_maraton_dag.py    # DefiniciÃ³n del workflow Airflow
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ __init__.py             # Hace de scripts un paquete Python
â”‚   â””â”€â”€ pipeline_tasks.py       # LÃ³gica de negocio (Bronze/Silver/Gold)
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ bronze/                 # Datos crudos
â”‚   â”‚   â””â”€â”€ resultados_raw.csv
â”‚   â”œâ”€â”€ silver/                 # Datos limpios
â”‚   â”‚   â””â”€â”€ resultados_clean.csv
â”‚   â””â”€â”€ gold/                   # KPIs
â”‚       â”œâ”€â”€ kpi_estadisticas_generales.csv
â”‚       â”œâ”€â”€ kpi_tiempo_por_categoria.csv
â”‚       â”œâ”€â”€ kpi_top5_por_genero.csv
â”‚       â”œâ”€â”€ kpi_distribucion_edad.csv
â”‚       â””â”€â”€ kpi_top10_ritmo.csv
â”‚
â”œâ”€â”€ logs/                       # Logs de Airflow
â”œâ”€â”€ docker-compose.yaml         # OrquestaciÃ³n de contenedores
â”œâ”€â”€ Dockerfile                  # Imagen personalizada
â”œâ”€â”€ requirements.txt            # Dependencias Python
â””â”€â”€ README.md                   # Este archivo
```

---

## ğŸ”§ Comandos Ãštiles

```bash
# Ver logs de un servicio especÃ­fico
docker compose logs -f airflow-scheduler

# Reiniciar Airflow (si cambias cÃ³digo en dags/)
docker compose restart airflow-scheduler airflow-webserver

# Detener todo
docker compose down

# Detener y eliminar volÃºmenes (reset completo)
docker compose down -v

# Entrar a un contenedor para debugging
docker compose exec airflow-scheduler bash

# Ejecutar el pipeline manualmente desde CLI
docker compose exec airflow-scheduler airflow dags trigger pipeline_media_maraton_la_serena_2024
```

---

## ğŸ› Troubleshooting

### El DAG no aparece en la UI
```bash
# Verificar errores de sintaxis
docker compose exec airflow-scheduler python /opt/airflow/dags/media_maraton_dag.py

# Ver logs del scheduler
docker compose logs airflow-scheduler | grep -i error
```

### Error de importaciÃ³n de mÃ³dulos
```bash
# Verificar que PYTHONPATH estÃ© configurado
docker compose exec airflow-scheduler echo $PYTHONPATH
# Debe mostrar: /opt/airflow/scripts
```

### La base de datos no inicializa
```bash
# Reiniciar el init
docker compose down -v
docker compose up -d
```

---
## ğŸ“¸ Capturas 

### DAG Cargado Correctamente en Airflow

### Vista Graph del Pipeline

![Graph](media_maraton_pipeline/dags/Airflow_graph.png)

---

## ğŸ“ˆ PrÃ³ximos Pasos (Ideas para extender)

- [ ] Conectar a datos reales via API
- [ ] Agregar tests con pytest
- [ ] Implementar alertas de Slack
- [ ] Crear dashboard en Streamlit/Metabase
- [ ] AÃ±adir capa de Data Quality con Great Expectations
- [ ] Migrar a cloud (AWS MWAA, GCP Composer)

---

## ğŸ‘¨â€ğŸ’» Autor

**Tu Nombre** - *Marcelo Rivera Vega*

---

## ğŸ“œ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para detalles.

---

## ğŸ™ Agradecimientos

- Organizadores de la Media MaratÃ³n La Serena
- Comunidad de Apache Airflow

---

*Â¿Te fue Ãºtil este proyecto? Â¡Dale una â­ y compÃ¡rtelo!*
