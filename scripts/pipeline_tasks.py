"""
pipeline_tasks.py
=================
Funciones de procesamiento para el Pipeline Media MaratÃ³n La Serena 2024.

Este mÃ³dulo implementa la arquitectura MedallÃ³n (Bronze â†’ Silver â†’ Gold)
con funciones puras, bien documentadas y con manejo de errores.

Autor: Marcelo Rivera Vega
Fecha: 2025
"""

import re
import logging
from pathlib import Path
from datetime import datetime
from typing import Optional

import pandas as pd

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CONFIGURACIÃ“N DE LOGGING
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Configuramos el logger para este mÃ³dulo.
# Esto nos permite rastrear quÃ© estÃ¡ pasando en cada paso del pipeline.
# En producciÃ³n, estos logs son INVALUABLES para debugging.

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CONFIGURACIÃ“N DE RUTAS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Usamos pathlib.Path porque:
# 1. Es multiplataforma (Windows, Linux, Mac)
# 2. Ofrece mÃ©todos Ãºtiles como .exists(), .mkdir(), etc.
# 3. Se puede concatenar con / de forma elegante

# La base es /opt/airflow dentro del contenedor Docker
BASE_PATH = Path("/opt/airflow/data")
BRONZE_PATH = BASE_PATH / "bronze"
SILVER_PATH = BASE_PATH / "silver"
GOLD_PATH = BASE_PATH / "gold"


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CAPA BRONZE: INGESTA DE DATOS CRUDOS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def process_bronze() -> str:
    """
    Capa Bronze: Ingesta de datos crudos.
    
    En un escenario real, aquÃ­ podrÃ­as:
    - Descargar archivos de un SFTP
    - Consultar una API externa
    - Leer de un bucket S3
    
    Para este tutorial, simulamos la ingesta creando el archivo
    con datos "sucios" tal como vendrÃ­an del mundo real.
    
    Returns:
        str: Ruta del archivo creado en la capa Bronze.
        
    Raises:
        Exception: Si hay un error al crear el archivo.
    """
    logger.info("ğŸ¥‰ Iniciando proceso BRONZE - Ingesta de datos crudos")
    
    try:
        # Creamos el directorio si no existe
        # parents=True crea directorios padres si faltan
        # exist_ok=True no lanza error si ya existe
        BRONZE_PATH.mkdir(parents=True, exist_ok=True)
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # DATOS SIMULADOS - Tal como vendrÃ­an del "mundo real"
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Observa los problemas que tenemos que resolver:
        # 1. "CategorÃ­a" y "Dorsal" estÃ¡n pegados en una sola celda
        # 2. Algunos nombres estÃ¡n en minÃºsculas
        # 3. El formato del tiempo es string "H:MM:SS"
        # 4. Las posiciones tienen el sÃ­mbolo "Âº"
        
        raw_data = [
            # [Pos General, Pos CategorÃ­a, Nombre, CategorÃ­a+Dorsal, Tiempo]
            ["1Âº", "1Âº", "Carlos AndrÃ©s DÃ­az Moreno", "Varones 18 a 29 aÃ±osdorsal: 2001", "1:12:45"],
            ["2Âº", "1Âº", "Miguel Ãngel Torres", "Varones 30 a 39 aÃ±osdorsal: 2102", "1:15:22"],
            ["3Âº", "2Âº", "Juan Pablo Soto Vera", "Varones 18 a 29 aÃ±osdorsal: 2015", "1:16:08"],
            ["4Âº", "2Âº", "Roberto Carlos MuÃ±oz", "Varones 30 a 39 aÃ±osdorsal: 2156", "1:18:33"],
            ["5Âº", "1Âº", "Andrea Paz GonzÃ¡lez", "Damas 18 a 29 aÃ±osdorsal: 2201", "1:19:45"],
            ["15Âº", "3Âº", "Pedro JosÃ© RamÃ­rez", "Varones 30 a 39 aÃ±osdorsal: 2178", "1:25:12"],
            ["22Âº", "1Âº", "MarÃ­a JosÃ© PÃ©rez Silva", "Damas 30 a 39 aÃ±osdorsal: 2245", "1:28:56"],
            ["35Âº", "1Âº", "Francisco Javier LÃ³pez", "Varones 40 a 49 aÃ±osdorsal: 2301", "1:32:18"],
            ["48Âº", "2Âº", "Carmen Gloria Fuentes", "Damas 30 a 39 aÃ±osdorsal: 2267", "1:35:44"],
            ["56Âº", "4Âº", "AndrÃ©s Felipe Castillo", "Varones 30 a 39 aÃ±osdorsal: 2189", "1:37:22"],
            ["72Âº", "2Âº", "Patricia Andrea NÃºÃ±ez", "Damas 40 a 49 aÃ±osdorsal: 2312", "1:40:15"],
            ["89Âº", "5Âº", "Diego Alejandro Vera", "Varones 30 a 39 aÃ±osdorsal: 2195", "1:42:58"],
            ["127Âº", "47Âº", "Abel Ballon Aguirre", "Varones 30 a 39 aÃ±osdorsal: 2395", "1:46:32"],
            ["145Âº", "3Âº", "Claudia Marcela Rojas", "Damas 40 a 49 aÃ±osdorsal: 2334", "1:49:18"],
            ["171Âº", "43Âº", "Alberto Ignacio Salas Nicolau", "Varones 40 a 49 aÃ±osdorsal: 2296", "1:52:08"],
            ["198Âº", "12Âº", "Valentina Paz Morales", "Damas 18 a 29 aÃ±osdorsal: 2223", "1:55:42"],
            ["215Âº", "8Âº", "JosÃ© Manuel Contreras", "Varones 50 a 59 aÃ±osdorsal: 2401", "1:58:15"],
            ["234Âº", "4Âº", "Rosa Elena MartÃ­nez", "Damas 40 a 49 aÃ±osdorsal: 2356", "2:02:33"],
            ["256Âº", "15Âº", "Sergio Antonio Pizarro", "Varones 50 a 59 aÃ±osdorsal: 2418", "2:06:48"],
            ["266Âº", "19Âº", "alexandrina vivar diaz", "Damas 40 a 49 aÃ±osdorsal: 2084", "2:09:40"],
            ["278Âº", "1Âº", "Manuel Eduardo Lagos", "Varones 60+ aÃ±osdorsal: 2501", "2:12:22"],
            ["289Âº", "5Âº", "Isabel Cristina Araya", "Damas 50 a 59 aÃ±osdorsal: 2445", "2:15:55"],
            ["301Âº", "2Âº", "HÃ©ctor RaÃºl Mendoza", "Varones 60+ aÃ±osdorsal: 2512", "2:20:18"],
            ["315Âº", "1Âº", "Teresa de JesÃºs Campos", "Damas 60+ aÃ±osdorsal: 2521", "2:25:42"],
            ["328Âº", "6Âº", "Gabriela Fernanda RÃ­os", "Damas 50 a 59 aÃ±osdorsal: 2467", "2:30:15"],
        ]
        
        # Creamos el DataFrame con nombres de columnas descriptivos
        # pero que reflejan el "problema" de la data cruda
        df_raw = pd.DataFrame(
            raw_data,
            columns=[
                "pos_general",
                "pos_categoria", 
                "nombre_corredor",
                "categoria_dorsal",  # Â¡Este es el campo problemÃ¡tico!
                "tiempo_oficial"
            ]
        )
        
        # Guardamos como CSV (simulando el archivo que recibirÃ­amos)
        output_file = BRONZE_PATH / "resultados_raw.csv"
        df_raw.to_csv(output_file, index=False)
        
        logger.info(f"âœ… Bronze completado: {len(df_raw)} registros guardados en {output_file}")
        
        # Retornamos la ruta como string para que Airflow pueda pasarla entre tareas
        return str(output_file)
        
    except Exception as e:
        # Logueamos el error con nivel ERROR para fÃ¡cil identificaciÃ³n
        logger.error(f"âŒ Error en proceso Bronze: {str(e)}")
        # Re-lanzamos la excepciÃ³n para que Airflow marque la tarea como fallida
        raise


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CAPA SILVER: LIMPIEZA Y TRANSFORMACIÃ“N
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _parse_categoria_dorsal(texto: str) -> tuple[str, str, str, Optional[int]]:
    """
    FunciÃ³n auxiliar para parsear el campo 'categoria_dorsal'.
    
    Esta funciÃ³n usa REGEX (expresiones regulares) para extraer:
    - GÃ©nero (Varones/Damas)
    - Rango de edad (ej: "30 a 39 aÃ±os")
    - NÃºmero de dorsal
    
    Args:
        texto: String con formato "Varones 30 a 39 aÃ±osdorsal: 2395"
        
    Returns:
        Tupla con (genero, rango_edad, categoria_completa, dorsal)
        
    Ejemplo:
        >>> _parse_categoria_dorsal("Varones 30 a 39 aÃ±osdorsal: 2395")
        ('Varones', '30 a 39 aÃ±os', 'Varones 30 a 39 aÃ±os', 2395)
    """
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # EXPLICACIÃ“N DEL REGEX
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ^(Varones|Damas)  â†’ Captura "Varones" o "Damas" al inicio
    # \s+               â†’ Uno o mÃ¡s espacios
    # (.+?)             â†’ Captura el rango de edad (non-greedy con ?)
    # dorsal:\s*        â†’ La palabra "dorsal:" seguida de espacios opcionales
    # (\d+)             â†’ Captura uno o mÃ¡s dÃ­gitos (el nÃºmero de dorsal)
    # $                 â†’ Fin del string
    
    pattern = r'^(Varones|Damas)\s+(.+?)dorsal:\s*(\d+)$'
    
    match = re.match(pattern, texto, re.IGNORECASE)
    
    if match:
        genero = match.group(1).capitalize()  # "varones" â†’ "Varones"
        rango_edad = match.group(2).strip()   # Removemos espacios extra
        dorsal = int(match.group(3))          # Convertimos a entero
        categoria_completa = f"{genero} {rango_edad}"
        
        return genero, rango_edad, categoria_completa, dorsal
    else:
        # Si el regex no hace match, retornamos valores por defecto
        logger.warning(f"âš ï¸ No se pudo parsear: {texto}")
        return "Desconocido", "Desconocido", texto, None


def _tiempo_a_segundos(tiempo_str: str) -> int:
    """
    Convierte un tiempo en formato "H:MM:SS" a segundos totales.
    
    Esto es Ãºtil para:
    1. Hacer cÃ¡lculos matemÃ¡ticos (promedios, diferencias)
    2. Ordenar correctamente los tiempos
    3. Comparar rendimientos
    
    Args:
        tiempo_str: Tiempo en formato "H:MM:SS" o "HH:MM:SS"
        
    Returns:
        Total de segundos como entero
        
    Ejemplo:
        >>> _tiempo_a_segundos("1:30:00")
        5400
    """
    partes = tiempo_str.split(':')
    
    if len(partes) == 3:
        horas, minutos, segundos = map(int, partes)
        return horas * 3600 + minutos * 60 + segundos
    elif len(partes) == 2:
        # Por si viene como "MM:SS" (menos de una hora)
        minutos, segundos = map(int, partes)
        return minutos * 60 + segundos
    else:
        logger.warning(f"âš ï¸ Formato de tiempo no reconocido: {tiempo_str}")
        return 0


def _calcular_ritmo(segundos_totales: int, distancia_km: float = 21.1) -> str:
    """
    Calcula el ritmo promedio (min/km) a partir del tiempo total.
    
    El ritmo es una mÃ©trica clave para corredores. Un maratonista
    elite corre a ~3:00 min/km, un amateur a ~6:00 min/km.
    
    Args:
        segundos_totales: Tiempo total de carrera en segundos
        distancia_km: Distancia de la carrera (21.1 km para media maratÃ³n)
        
    Returns:
        String con formato "M:SS" representando minutos por kilÃ³metro
    """
    if segundos_totales <= 0 or distancia_km <= 0:
        return "0:00"
    
    segundos_por_km = segundos_totales / distancia_km
    minutos = int(segundos_por_km // 60)
    segundos = int(segundos_por_km % 60)
    
    return f"{minutos}:{segundos:02d}"


def process_silver(bronze_file: Optional[str] = None) -> str:
    """
    Capa Silver: Limpieza y transformaciÃ³n de datos.
    
    Esta es la capa donde ocurre la "magia" de la limpieza.
    Tomamos datos sucios y los convertimos en datos estructurados.
    
    Transformaciones aplicadas:
    1. Separar 'categoria_dorsal' en columnas individuales
    2. Limpiar posiciones (quitar 'Âº')
    3. Convertir tiempo a segundos para cÃ¡lculos
    4. Calcular ritmo (min/km)
    5. Normalizar nombres (Title Case)
    
    Args:
        bronze_file: Ruta al archivo Bronze (opcional, usa default si no se pasa)
        
    Returns:
        str: Ruta del archivo creado en la capa Silver
    """
    logger.info("ğŸ¥ˆ Iniciando proceso SILVER - Limpieza de datos")
    
    try:
        # Definimos rutas de entrada y salida
        input_file = Path(bronze_file) if bronze_file else BRONZE_PATH / "resultados_raw.csv"
        SILVER_PATH.mkdir(parents=True, exist_ok=True)
        output_file = SILVER_PATH / "resultados_clean.csv"
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # PASO 1: Lectura del archivo Bronze
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        logger.info(f"ğŸ“– Leyendo archivo: {input_file}")
        df = pd.read_csv(input_file)
        logger.info(f"   Registros leÃ­dos: {len(df)}")
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # PASO 2: Separar categoria_dorsal en columnas
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Usamos .apply() para aplicar nuestra funciÃ³n a cada fila
        # El resultado es una Serie de tuplas que expandimos con .tolist()
        
        logger.info("ğŸ”§ Parseando campo categoria_dorsal...")
        
        parsed_data = df['categoria_dorsal'].apply(_parse_categoria_dorsal)
        
        # Convertimos las tuplas a columnas separadas
        df['genero'] = parsed_data.apply(lambda x: x[0])
        df['rango_edad'] = parsed_data.apply(lambda x: x[1])
        df['categoria'] = parsed_data.apply(lambda x: x[2])
        df['dorsal'] = parsed_data.apply(lambda x: x[3])
        
        # Eliminamos la columna original (ya no la necesitamos)
        df = df.drop(columns=['categoria_dorsal'])
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # PASO 3: Limpiar posiciones
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Removemos el sÃ­mbolo "Âº" y convertimos a entero
        
        logger.info("ğŸ”§ Limpiando columnas de posiciÃ³n...")
        
        df['pos_general'] = df['pos_general'].str.replace('Âº', '').astype(int)
        df['pos_categoria'] = df['pos_categoria'].str.replace('Âº', '').astype(int)
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # PASO 4: Normalizar nombres
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # .str.title() convierte "JUAN PEREZ" o "juan perez" a "Juan Perez"
        
        logger.info("ğŸ”§ Normalizando nombres...")
        df['nombre_corredor'] = df['nombre_corredor'].str.title()
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # PASO 5: Procesar tiempos
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        logger.info("ğŸ”§ Calculando mÃ©tricas de tiempo...")
        
        df['tiempo_segundos'] = df['tiempo_oficial'].apply(_tiempo_a_segundos)
        df['ritmo_min_km'] = df['tiempo_segundos'].apply(_calcular_ritmo)
        
        # Calculamos la velocidad en km/h (otra mÃ©trica Ãºtil)
        df['velocidad_kmh'] = round(21.1 / (df['tiempo_segundos'] / 3600), 2)
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # PASO 6: Reordenar columnas para mejor legibilidad
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        columnas_ordenadas = [
            'pos_general',
            'pos_categoria',
            'dorsal',
            'nombre_corredor',
            'genero',
            'rango_edad',
            'categoria',
            'tiempo_oficial',
            'tiempo_segundos',
            'ritmo_min_km',
            'velocidad_kmh'
        ]
        
        df = df[columnas_ordenadas]
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # PASO 7: Guardar resultado
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        df.to_csv(output_file, index=False)
        
        logger.info(f"âœ… Silver completado: {len(df)} registros guardados en {output_file}")
        
        # Mostramos un preview de los datos limpios
        logger.info(f"ğŸ“Š Preview de datos limpios:\n{df.head(3).to_string()}")
        
        return str(output_file)
        
    except FileNotFoundError:
        logger.error(f"âŒ Archivo no encontrado: {input_file}")
        raise
    except Exception as e:
        logger.error(f"âŒ Error en proceso Silver: {str(e)}")
        raise


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CAPA GOLD: AGREGACIONES Y KPIs
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def process_gold(silver_file: Optional[str] = None) -> dict:
    """
    Capa Gold: GeneraciÃ³n de KPIs y agregaciones de negocio.
    
    AquÃ­ creamos las mÃ©tricas que consumirÃ­an dashboards o reportes.
    Cada KPI se guarda como un archivo CSV separado.
    
    KPIs generados:
    1. EstadÃ­sticas generales de la carrera
    2. Tiempo promedio por categorÃ­a
    3. Top 5 mÃ¡s rÃ¡pidos por gÃ©nero
    4. DistribuciÃ³n de participantes por rango de edad
    5. Top 10 mejores ritmos overall
    
    Args:
        silver_file: Ruta al archivo Silver (opcional)
        
    Returns:
        dict: Diccionario con las rutas de los archivos Gold generados
    """
    logger.info("ğŸ¥‡ Iniciando proceso GOLD - GeneraciÃ³n de KPIs")
    
    try:
        # Definimos rutas
        input_file = Path(silver_file) if silver_file else SILVER_PATH / "resultados_clean.csv"
        GOLD_PATH.mkdir(parents=True, exist_ok=True)
        
        # Lectura de datos limpios
        logger.info(f"ğŸ“– Leyendo archivo: {input_file}")
        df = pd.read_csv(input_file)
        
        # Diccionario para almacenar rutas de archivos generados
        output_files = {}
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # KPI 1: EstadÃ­sticas Generales
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        logger.info("ğŸ“Š Generando KPI: EstadÃ­sticas Generales...")
        
        stats_generales = {
            'total_participantes': len(df),
            'total_varones': len(df[df['genero'] == 'Varones']),
            'total_damas': len(df[df['genero'] == 'Damas']),
            'tiempo_ganador': df['tiempo_oficial'].iloc[0],
            'tiempo_ultimo': df['tiempo_oficial'].iloc[-1],
            'tiempo_promedio_segundos': round(df['tiempo_segundos'].mean(), 2),
            'ritmo_promedio': _calcular_ritmo(int(df['tiempo_segundos'].mean())),
            'velocidad_promedio_kmh': round(df['velocidad_kmh'].mean(), 2),
            'fecha_proceso': datetime.now().isoformat()
        }
        
        df_stats = pd.DataFrame([stats_generales])
        stats_file = GOLD_PATH / "kpi_estadisticas_generales.csv"
        df_stats.to_csv(stats_file, index=False)
        output_files['estadisticas_generales'] = str(stats_file)
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # KPI 2: Tiempo Promedio por CategorÃ­a
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        logger.info("ğŸ“Š Generando KPI: Tiempo Promedio por CategorÃ­a...")
        
        # Agrupamos por categorÃ­a y calculamos mÃ©tricas
        df_por_categoria = df.groupby('categoria').agg({
            'tiempo_segundos': ['mean', 'min', 'max', 'count'],
            'velocidad_kmh': 'mean'
        }).round(2)
        
        # Aplanamos los nombres de columnas multinivel
        df_por_categoria.columns = [
            'tiempo_promedio_seg', 
            'tiempo_mejor_seg', 
            'tiempo_peor_seg', 
            'cantidad_corredores',
            'velocidad_promedio_kmh'
        ]
        
        # AÃ±adimos el ritmo promedio como columna legible
        df_por_categoria['ritmo_promedio'] = df_por_categoria['tiempo_promedio_seg'].apply(
            lambda x: _calcular_ritmo(int(x))
        )
        
        df_por_categoria = df_por_categoria.reset_index()
        
        categoria_file = GOLD_PATH / "kpi_tiempo_por_categoria.csv"
        df_por_categoria.to_csv(categoria_file, index=False)
        output_files['tiempo_por_categoria'] = str(categoria_file)
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # KPI 3: Top 5 por GÃ©nero
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        logger.info("ğŸ“Š Generando KPI: Top 5 por GÃ©nero...")
        
        # Top 5 Varones
        top_varones = df[df['genero'] == 'Varones'].nsmallest(5, 'tiempo_segundos')[
            ['pos_general', 'nombre_corredor', 'categoria', 'tiempo_oficial', 'ritmo_min_km']
        ]
        top_varones['ranking_genero'] = range(1, len(top_varones) + 1)
        
        # Top 5 Damas
        top_damas = df[df['genero'] == 'Damas'].nsmallest(5, 'tiempo_segundos')[
            ['pos_general', 'nombre_corredor', 'categoria', 'tiempo_oficial', 'ritmo_min_km']
        ]
        top_damas['ranking_genero'] = range(1, len(top_damas) + 1)
        
        # Combinamos en un solo archivo
        top_varones['genero'] = 'Varones'
        top_damas['genero'] = 'Damas'
        df_top_genero = pd.concat([top_varones, top_damas])
        
        top_file = GOLD_PATH / "kpi_top5_por_genero.csv"
        df_top_genero.to_csv(top_file, index=False)
        output_files['top5_por_genero'] = str(top_file)
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # KPI 4: DistribuciÃ³n por Rango de Edad
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        logger.info("ğŸ“Š Generando KPI: DistribuciÃ³n por Rango de Edad...")
        
        df_distribucion = df.groupby(['rango_edad', 'genero']).size().reset_index(name='cantidad')
        df_distribucion['porcentaje'] = round(
            df_distribucion['cantidad'] / len(df) * 100, 2
        )
        
        distribucion_file = GOLD_PATH / "kpi_distribucion_edad.csv"
        df_distribucion.to_csv(distribucion_file, index=False)
        output_files['distribucion_edad'] = str(distribucion_file)
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # KPI 5: Top 10 Mejores Ritmos
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        logger.info("ğŸ“Š Generando KPI: Top 10 Mejores Ritmos...")
        
        df_top_ritmo = df.nsmallest(10, 'tiempo_segundos')[
            ['pos_general', 'dorsal', 'nombre_corredor', 'categoria', 
             'tiempo_oficial', 'ritmo_min_km', 'velocidad_kmh']
        ]
        
        ritmo_file = GOLD_PATH / "kpi_top10_ritmo.csv"
        df_top_ritmo.to_csv(ritmo_file, index=False)
        output_files['top10_ritmo'] = str(ritmo_file)
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Resumen final
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        logger.info("âœ… Gold completado. Archivos generados:")
        for nombre, ruta in output_files.items():
            logger.info(f"   ğŸ“ {nombre}: {ruta}")
        
        return output_files
        
    except FileNotFoundError:
        logger.error(f"âŒ Archivo no encontrado: {input_file}")
        raise
    except Exception as e:
        logger.error(f"âŒ Error en proceso Gold: {str(e)}")
        raise


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# FUNCIÃ“N DE PRUEBA LOCAL
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Este bloque solo se ejecuta si corres el archivo directamente
# Es Ãºtil para testing local sin Airflow

if __name__ == "__main__":
    print("=" * 60)
    print("ğŸƒ Pipeline Media MaratÃ³n La Serena 2024 - Test Local")
    print("=" * 60)
    
    # Para pruebas locales, ajustamos las rutas
    BASE_PATH = Path("./data")
    BRONZE_PATH = BASE_PATH / "bronze"
    SILVER_PATH = BASE_PATH / "silver"  
    GOLD_PATH = BASE_PATH / "gold"
    
    # Ejecutamos el pipeline completo
    print("\n[1/3] Ejecutando Bronze...")
    bronze_output = process_bronze()
    
    print("\n[2/3] Ejecutando Silver...")
    silver_output = process_silver(bronze_output)
    
    print("\n[3/3] Ejecutando Gold...")
    gold_outputs = process_gold(silver_output)
    
    print("\n" + "=" * 60)
    print("âœ… Pipeline completado exitosamente!")
    print("=" * 60)

